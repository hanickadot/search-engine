<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>search C++ standard draft</title>
		
		<link rel="stylesheet" href="style.css">
		<script src="d3.v7.js"></script>
		<script src="string.js"></script>
		<style>
			.ngrams {
				border: 1px solid black;
				padding: 20px;
				margin: 20px;
			}
			
			.ngrams > span {
				border: 1px solid black;
				border-radius: 10px;
				padding: 5px;
				margin: 5px;
				font-family: Monaco;
				font-size: 11px;
				background-color: lightgray;
			}
			
			.ngrams > span > b {
				background-color: black;
				color: white;
				border-radius: 20px;
				padding: 2px 5px;
				margin-left: 5px;
			}
		</style>
	</head>
	<body>
		<script>	
			function binary_search(needle, arr, compare, merge) {
				let start = 0;
				let end = arr.length - 1;
				while (start <= end) {
					let mid = Math.floor((start + end) / 2);
					const relationship = compare(needle, arr[mid]);
					
					if (relationship === 0) {
						return merge(needle, arr[mid]);
					}
					
					if (relationship >= 0) {
						start = mid + 1;
					}
					
					if (relationship <= 0) {
						end = mid - 1;
					}
				}
				return undefined;
			}
			
			function intersection_with_search(lhs, rhs, compare, merge, limit) {
				let output = [];
				
				for (let i = 0; i != lhs.length; ++i) {
					const left = lhs[i];
					const result = binary_search(left, rhs, compare, merge);
					if (result !== undefined) {
						output.push(result);
						if (output.length === limit) {
							return output;
						}
					}
				}
				
				return output;
			}
			
			function intersection_helper(lhs, rhs, compare, merge, limit) {
				const linear_cost = lhs.length + rhs.length;
				const log_cost = lhs.length * Math.log(rhs.length);
				
				// in case we are comparing small set with really big set O(n * log m) is better than O(n + m)
				if (log_cost < linear_cost) {
					return intersection_with_search(lhs, rhs, compare, merge, limit);
				}
				
				const lhs_it = lhs[Symbol.iterator]();
				const rhs_it = rhs[Symbol.iterator]();
				
				let output = [];
				
				let left = lhs_it.next();
				let right = rhs_it.next();
				
				while (!left.done && !right.done) {
					const relationship = compare(left.value, right.value);
					
					if (relationship === 0) {
						output.push(merge(left.value, right.value));
						
						if (output.length === limit) {
							return output;
						}
					}
					
					if (relationship >= 0) {
						right = rhs_it.next();
					}
					
					if (relationship <= 0) {
						left = lhs_it.next();
					}
				}
				
				return output;
			}
					

			
			
			const urls = fetch("index/urls.json", {cache: "force-cache"}).then((response) => response.json());
			const outliers = fetch("index/outliers.json", {cache: "force-cache"}).then((response) => { 
				if (response.status == 404) {
					return [];
				}
				return response.json();
			});
			
			// this will download and map ngram with offset
			async function download_index_for(ngram) {
				const url = "index/leaves/"+ngram+".json";
				const response = await fetch(url, {cache: "force-cache"});
				
				if (response.status == 404) {
					return [];
				}
				
				if (!response.ok) {
					console.warn("can't download: "+url);
					return [];
				}
				
				return await response.json();
			}
			
			function format_document_target_id_file(id) {
				return (("00000" + id).slice(-5))
			}
			
			async function download_targets_for(document_id) {
				const url = "index/targets/"+format_document_target_id_file(document_id)+".json";
				const response = await fetch(url, {cache: "force-cache"})
				
				if (response.status == 404) {
					return [];
				}
				
				if (!response.ok) {
					console.warn("can't download: "+url);
					return [];
				}
				
				return await response.json();
			}
			
			function sort_by_length(sets) {
				return sets.sort((lhs, rhs) => (lhs.length - rhs.length));
			}
			
			function set_intersection(sets) {
				if (sets.length === 0) {
					return [];
				}
				
				const ngram_intersection = (lhs, rhs) => {
					const compare = (l, r) => {
						const result = l.id - r.id;
					
						if (result === 0) {
							return l.position - r.position;
						}
					
						return result;
					};
				
					return intersection_helper(lhs, rhs, compare, (l, r) => l);
				}
				
				
				return sets.reduce(ngram_intersection)
			}
			
			function document_intersection(sets) {
				if (sets.length === 0) {
					return [];
				}
				
				const helper = (lhs, rhs) => {
					const compare = (l, r) => {
						if (l.id === r.id) {
							return 0;
						}
					
						if (l.id < r.id) {
							return -1;
						} else {
							return 1;
						}
					};
				
					const merge = (l, r) => {
						l.count += r.count;
						l.ratio = l.count / l.ngrams;
						l.positions.push(r.positions[0]);
						return l;
					};
				
					return intersection_helper(lhs, rhs, compare, merge, 0);
				};
				
				const sorted = sort_by_length(sets);
				
				// we don't need to sort documents as it's already sorted in the index
				return sorted.reduce(helper).sort((lhs, rhs) => (rhs.ratio - lhs.ratio));
			}
			
			async function reduce_documents(sets, query_length) {
				if (sets.length === 0) {
					return [];
				}
				
				
				const documents = await urls;
				
				const result = sets.reduce((context, entry) => {
					
					const id = entry.id;
					const position = entry.position;
					// in case we don't have context yet
					
					const default_count = query_length;
					
					
					if (context[id] === undefined) {
						
						context[id] = {
							count: default_count,
							id: id,
							url: (documents[id][0]),
							ngrams: (documents[id][1]),
							first_position: position,
							positions: [[position]],
							ratio: default_count / (documents[id][1])
						};
					} else {
						context[id].count+=default_count;
						context[id].ratio = context[id].count / context[id].ngrams;
						context[id].first_position = context[id].first_position < position ? context[id].first_position : position;
						context[id].positions[0].push(position);
					}
					
					// we drag whole context for each doc with ourself
					return context;
				},{});
				
				// we got context object, but we need to convert it to array
				return Object.entries(result).map((v) => v[1]);
			}
			
			async function optimize_and_download(ngrams, outliers_promise, size) {
				const outliers = await outliers_promise;
				
				const info = ngrams.map((ngram, off) => ({ngram: ngram, cost: outliers[ngram], first: off, enabled: true}));
				let unique = new Set(ngrams);
				let coverage = new Array(ngrams.length + size - 1).fill(0);
				
				const offset = [...new Array(size).keys()];
				
				// fill coverage
				ngrams.forEach((ngram, off) => { offset.forEach((n) => coverage[off + n]++) });
				
				const remove_ngram = (ngram) => {
					info.filter((item) => item.ngram == ngram).forEach((item) => {
						offset.forEach((off) => { coverage[off + item.first]--; });
					});
				};
				
				// remove some if possible
				const opportunity = (ngram) => {
					//let unique_covered_boxes = 0;
					const ngram_and_opportunity = {ngram: ngram, opportunity: info.filter((item) => item.ngram == ngram).reduce((previous_cost, item) => {
						const unique_hit = offset.reduce((acc, off) => acc + (coverage[item.first + off] == 1), 0);
						if (unique_hit > 0) {
							return 0; // we can't remove this element
						} else {
							return previous_cost * (item.cost ? (2 ** item.cost) : 1);
						}
					}, 1)};
					
					//console.log(`opportunity: ${ngram_and_opportunity.ngram} -> ${ngram_and_opportunity.opportunity}`);
					return ngram_and_opportunity;
				};
				
				// loop thru until nothing can be removed
				for (;;) {
					const candidate = [...unique].reduce((previous, ngram) => {
						const item = opportunity(ngram);
						if (item.opportunity == 0) {
							return previous;
						}
						if (previous == undefined) {
							return item;
						}
						if (previous.opportunity > item.opportunity) {
							return previous;
						} else {
							return item;
						}
					}, undefined);
				
					if (candidate === undefined) {
						break;
					}
				
					//console.log(`removal: ${candidate.ngram} (${candidate.opportunity})`);
					unique.delete(candidate.ngram);
					remove_ngram(candidate.ngram);
				}
				
				//return ngrams;
				const needed = await Promise.all([...unique].map((ngram) => ({ngram: ngram, promise: download_index_for(ngram)})));
				
				
				// offset
				const mapped_ngrams = ngrams.map((ngram, offset) => ({ngram_and_promise: needed.find((item) => item.ngram == ngram), offset: offset})).filter((item) => item.ngram_and_promise !== undefined);
				
				return await Promise.all(mapped_ngrams.map(async (item) => {
					const entries = await item.ngram_and_promise.promise;
					
					// null means transparency for search (it can't be [] as we will be doing intersection)
					if (entries === null) {
						return entries;
					}
					
					return entries.map((entry) => ({id: entry[0], position: entry[1] - item.offset}));
				}));
			}
			
			async function list_of_documents_for_each_word(words, size = 3) {
				return Promise.all(words.map(async (word) => {
					// this access internet and download all ngrams indices for current word
					const ngrams_from_query = word.ngrams(size);
					const ngram_hits = await optimize_and_download(ngrams_from_query, outliers, size);
					const sorted_ngram_hits = sort_by_length(ngram_hits.filter(hit => hit !== null));
					const hits = set_intersection(sorted_ngram_hits);
					// we need to wait for all document list and then we produce list of unique documents for current word
					return reduce_documents(hits, ngrams_from_query.length + size - 1);
				}));
			}
			
			function find_nearest_target(documents, position, targets) {
				let candidate = "";
				console.log(documents);
				for (let i = 0; i != targets.length; ++i) {
					
					// TODO improve performance by binary search
					if (position > targets[i][0]) {
						candidate = targets[i][1];
					}
					if (position < targets[i][0]) {
						break;
					}
				}
				return candidate;
			}
			
			function lower_bound(needle, haystack, skip_start = 0) {
				let end = haystack.length;
				
				let start = skip_start;
				let count = end - start;
				
				//console.log("searching ("+start+","+end+")");
				while (count > 0) {
					//console.log("count = "+count);
					let it = start;
					let step =  Math.floor(count / 2);
					
					it += step;
					if (haystack[it][0] < needle) {
						start = ++it;
						count -= (step + 1);
					} else {
						count = step;
					}
				}
				
				if (start > 0) {
					return start - 1;
				}
				
				return end;
				
			}
		
			
			function find_first_common_target(positions, targets) {
				let sections = positions.map(set => {
					let start = 0;
					let output = [];
					let previous = undefined;
					
					
					for (let i = 0; i != set.length; ++i) {
						let needle = set[i];
						
						start = lower_bound(needle, targets, start);
						if (start == targets.length) {
							//console.log("not-found");
							break;
						}
						
						if (start === previous) {
							//console.log("skipped");
							continue;
						}
						
						//console.log("found");
						previous = start;
						
						output.push({first_position: targets[start][0], target: targets[start][1]});
					}
					return output;
				});
				
				
				const target_intersection = (lhs, rhs) => {
					const compare = (l, r) => {
						return l.first_position - r.first_position;
					};
				
					return intersection_helper(lhs, rhs, compare, (l, r) => l);
				};
			
				let r = sections.reduce(target_intersection);
				
				if (r.length == 0) {
					return [];
				}
				
				if (r[0].target === "") {
					r.shift();
				}
				
				return r.map((t) => t.target);
			}
			
			async function multiterm_search(text, size = 3, limit = 100) {
				// we are interested in words of certain size only
				const words = text.split_to_words().filter((word) => word.length >= size);
				// we intersect documents for each word to produce list of documents for search query
				const results = document_intersection(await list_of_documents_for_each_word(words, size));
				// download lists of targets... (but only for top N)
				//await Promise.all(results.slice(0, limit).map(async (doc) => { 
				//	const targets = await download_targets_for(doc.id);
				//	targets.unshift([0, ""]);
				//	doc.targets = find_first_common_target(doc.positions, targets);
				//	return doc;
				//}));
				
				return results;
			}
			
			function color_intensity(v) {
				const c = d3.hsl(d3.interpolateWarm(v));
				c.l = (c.l + 2) / 3;
				return c.formatHex();
			}
			
			function timeout(ms) {
			    return new Promise(resolve => setTimeout(resolve, ms));
			}
			
			async function sleep(ms) {
			    await timeout(ms);
			}
			
			let search_counter = 0;
			
			function search(text, output, limit = 99, size = 3) {
				
				const current_search = ++search_counter;
				const results = multiterm_search(text.toLowerCase(), size, limit);
				
				results.then((entries) => {
					if (current_search != search_counter) {
						return;
					}
					
					const first = entries.slice(0, limit);
					
					const max = first.reduce((context, entry) => entry.count > context ? entry.count : context, 0);
					
					window.location.hash = encodeURIComponent(text.toLowerCase());
					
					while (output.firstChild) {
						output.removeChild(output.firstChild);
					}
					
					first.forEach((entry) => {
						const text = document.createTextNode(decodeURIComponent(entry.url));
						const a = document.createElement("a");
					
						let url = entry.url;
						
						a.className = "normal";
						a.setAttribute("href",url);
						a.setAttribute("target","_blank");
					
						const li = document.createElement("li");
					
						a.appendChild(text);
					
						const count_info = document.createElement("span");
						count_info.className = "ratio";
						count_info.style="background-color: "+color_intensity(entry.count / entry.ngrams);
						const count_text = document.createTextNode((entry.count / entry.ngrams * 100).toFixed(2) + "%");
						count_info.appendChild(count_text);
						
						
						
						li.appendChild(a);
						li.appendChild(count_info);
						
						text.search_link_targets = download_targets_for(entry.id).then(async (targets) => {
							await sleep(Math.random() * 2000);
							
							targets.unshift([0, ""]);
							
							let common_targets = find_first_common_target(entry.positions, targets);
							//console.log(common_targets);
							common_targets.forEach((target) => {
								const target_info = document.createElement("a");
								target_info.setAttribute("href",url + "#" + target);
								target_info.setAttribute("target","_blank");
								target_info.className = "target";
								const hash = document.createTextNode("#");
								const hash_span = document.createElement("span");
								hash_span.appendChild(hash);
								target_info.appendChild(hash_span);
								const target_text = document.createTextNode(target);
								target_info.appendChild(target_text);
								li.appendChild(target_info);
							});
						});
						//	const targets = await download_targets_for(doc.id);
						//	targets.unshift([0, ""]);
						//	doc.targets = find_first_common_target(doc.positions, targets);
						//	return doc;
						
						//console.log(entry)
						//if (entry.targets) entry.targets.forEach((target) => {
						//	const target_info = document.createElement("a");
						//	target_info.setAttribute("href",url + "#" + target);
						//	target_info.setAttribute("target","_blank");
						//	target_info.className = "target";
						//	const hash = document.createTextNode("#");
						//	const hash_span = document.createElement("span");
						//	hash_span.appendChild(hash);
						//	target_info.appendChild(hash_span);
						//	const target_text = document.createTextNode(target);
						//	target_info.appendChild(target_text);
						//	li.appendChild(target_info);
						//});
						
						//if (targets != "#") {
						//	const target_info = document.createElement("span");
						//	target_info.className = "target";
						//	const target_text = document.createTextNode(target);
						//	target_info.appendChild(target_text);
						//	li.appendChild(target_info);
						//}
						
						output.appendChild(li);
					});
					
					if (entries.length > limit) {
						const total_count = document.createTextNode("... and "+(entries.length-limit) +" more hits ...");
						const total_count_span = document.createElement("span");
						total_count_span.className = "info";
						total_count_span.appendChild(total_count);
						output.appendChild(total_count_span)
					}
					
					
					
				});
			}
				
			//update();
		</script>
		<input id="searchbox" placeholder="search C++ standard draft" type="search" autofocus autocorrect="off" autocapitalize="none" spellcheck="false" oninput="search(this.value, search_result)"/>
		<ol id="search_result">
		</ol>
		<script>
			searchbox.value = decodeURIComponent(location.hash.replace(/^#/, ""));
			search(searchbox.value, search_result);
		</script>
	</body>	
</html>


